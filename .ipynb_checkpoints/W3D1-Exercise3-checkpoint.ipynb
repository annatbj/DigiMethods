{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Functions and Data\n",
    "\n",
    "Builds on exercises provided by programminghistorian.org. \n",
    "\n",
    "## 3.1 Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.1**: Write a function `is_number` that uses the `try` and `except` structure to return `True` of the input is a number, or print a relevant error statement and returns `None` if the input is not a number. Test your function on several cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to question 3.1.1\n",
    "# function is_number: first try \n",
    "def is_number(number):\n",
    "        try:\n",
    "            value=float(number)\n",
    "            print(\"this is a number\")\n",
    "        except ValueError:\n",
    "            print(\"Oh no, this is not a number\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a number\n"
     ]
    }
   ],
   "source": [
    "is_number(\"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a number\n",
      "None\n",
      "this is a number\n",
      "None\n",
      "this is a number\n",
      "None\n",
      "this is a number\n",
      "None\n",
      "Oh no, this is not a number\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Test integer\n",
    "print(is_number(3))\n",
    "#Test float\n",
    "print(is_number(1.6))\n",
    "#test negative number\n",
    "print(is_number(-88))\n",
    "#test number as string\n",
    "print(is_number(\"5.5\"))\n",
    "#test string\n",
    "print(is_number(\"five\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.2**: Write some test cases for your function. Did you have to change your function based on your test cases? If so, explain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to question 3.1.2\n",
    "#Yes we did, it was difficult and tough - it is possible to stringify numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.3**: Write a function `word_freq` that takes in a list of words and counts the frequency of each word in the list. Your function should return a dictionary with the word as the key and the count as the value. \n",
    "\n",
    "Hint: Useful string methods to look at is `count()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to question 3.1.3\n",
    "\"\"\"vi prøver at lave en word_freq-list\"\"\"\n",
    "def a_word_freq(word_list):\n",
    "    for words in word_list:\n",
    "        word_list.count(words)\n",
    "\n",
    "    print(len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annas_list=['as','bs','cs','as','as','bs','as','skole','skib','skak','sko','sko','skib','as','skib']\n",
    "type(annas_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annas_list.count('as')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "a_word_freq(annas_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEN GODE DER VIRKER\n",
    "def word_freq(wordlist):\n",
    "    dicti={}\n",
    "    for element in wordlist:\n",
    "        wordlistvariable={element:wordlist.count(element)}\n",
    "        dicti.update(wordlistvariable)\n",
    "    return(dicti)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as': 5, 'bs': 2, 'cs': 1, 'skole': 1, 'skib': 3, 'skak': 1, 'sko': 2}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq(annas_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([5, 2, 1, 1, 3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "annas_word_freq=dict(word_freq(annas_list))\n",
    "print(annas_word_freq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_list=[\"sol\",\"måne\",\"sol\",2.1,2.1,2.1,\"sol\",\"måne\"]\n",
    "type(big_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sol': 3, 'måne': 2, 2.1: 3}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq(big_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to do this could be by doing the following [done by the tutors]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wordo_freq(wordlist):\n",
    "    counti={}\n",
    "    for word in wordlist:\n",
    "        if word not in counti:\n",
    "            counti[word]=wordlist.count(word)\n",
    "    return counti\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as': 5, 'bs': 2, 'cs': 1, 'skole': 1, 'skib': 3, 'skak': 1, 'sko': 2}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordo_freq(annas_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A third option that did not work\n",
    "def better_word_freq(wordlist):\n",
    "    for keys in wordlist:\n",
    "        a=0\n",
    "        a+=wordlist.count(keys)\n",
    "    keyss=zip(list(keys),list(a))\n",
    "    dict(keyss)\n",
    "    print(keyss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.4**: Write a function  `sort_freq_dict` that takes a dictionary of key value pairs that are words and their frequencies. The function should turn the dictionary into a list of (freq, word) tuples, sorted highest to lowest by frequency. The function should return this list. \n",
    "\n",
    "Hint: list methods `sort()` and `reverse()` will be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to question 3.1.4 will come at a later point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will take the word_freq function from earlier and sort the entities' values (no.)\n",
    "# To do: dictionarize,\n",
    "# dictionaries CANNOT be reversed, neither can they be sorted. Therefore, we need to\n",
    "#write a function that (1) separates keys+values (or some other smart plan)\n",
    "#                        (2) sorts the values\n",
    "# (3) assign them to the CORRECT word... hmm...\n",
    "# Reverse turns the lists around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "awfv=sorted(annas_word_freq)\n",
    "#ovenstående tror jeg vil hjælpe i forhold til at sortere værdierne!\n",
    "#problemet er igen at få tingene til at holde sammen, det er ligesom æg\n",
    "#tuples kan få tingene til at hænge sammen-, så det skal være noget der skal gøres\n",
    "#for hvert element\n",
    "#element i liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 'as'), (2, 'bs'), (1, 'cs'), (1, 'skole'), (3, 'skib'), (1, 'skak'), (2, 'sko')]\n"
     ]
    }
   ],
   "source": [
    "listt=[(v,k) for k,v in annas_word_freq.items()]\n",
    "print(listt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 1, 1, 3, 1, 2]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(annas_word_freq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'cs'), (1, 'skak'), (1, 'skole'), (2, 'bs'), (2, 'sko'), (3, 'skib'), (5, 'as')]\n"
     ]
    }
   ],
   "source": [
    "listt.sort()\n",
    "print(listt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 'as'), (3, 'skib'), (2, 'sko'), (2, 'bs'), (1, 'skole'), (1, 'skak'), (1, 'cs')]\n"
     ]
    }
   ],
   "source": [
    "listt.reverse()\n",
    "print(listt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#above was the initial trials for commands to use. Below is my answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_freq_dict(my_dict):\n",
    "    #first I need to tuplify it with values as first key:\n",
    "    for element in my_dict:\n",
    "        listing=[(k,v) for v,k in my_dict.items()]\n",
    "        #then I need to sort them and put them in reverse order:\n",
    "    listing.sort()\n",
    "    listing.reverse()\n",
    "    #but I don't want the numbers to come first...\n",
    "    rightlisting=[(v,k) for k,v in listing]\n",
    "    \n",
    "    return rightlisting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('as', 5),\n",
       " ('skib', 3),\n",
       " ('sko', 2),\n",
       " ('bs', 2),\n",
       " ('skole', 1),\n",
       " ('skak', 1),\n",
       " ('cs', 1)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_freq_dict(annas_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is what the tutors did:\n",
    "#defining the function\n",
    "def sort_freq_dicto (freq_dict):\n",
    "    #creating an empty list\n",
    "    freq_list = []\n",
    "    \n",
    "    #looping through the dictionary and adding each value, key pair to the list\n",
    "    for key in freq_dict:\n",
    "        freq_list.append((freq_dict[key], key))\n",
    "    \n",
    "    #sorting the list\n",
    "    freq_list.sort()\n",
    "    #reversing the sort to be largest to smallest\n",
    "    freq_list.reverse()\n",
    "    \n",
    "    #returning the list\n",
    "    return freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'as'),\n",
       " (3, 'skib'),\n",
       " (2, 'sko'),\n",
       " (2, 'bs'),\n",
       " (1, 'skole'),\n",
       " (1, 'skak'),\n",
       " (1, 'cs')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_freq_dicto(annas_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.5**: Write a function called `remove_stop_words` that takes two lists of words as input (a word list and a stop word list). Your function should return a list of words with all the words in the word list except those found in the stop word list. \n",
    "\n",
    "Note: A stop word list is a list of common words (e.g. the, a, and, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['da', 'jeg', 'gik', 'ud', 'over', 'Langebro', 'var', 'jeg', 'i', 'tvivl', 'om', 'det', 'regnede,', 'men', 'det', 'er', 'jo', 'ikke', 'til', 'at', 'vide', 'som', 'man', 'ved,', 'så', 'det', 'er', 'godt', 'nok.']\n"
     ]
    }
   ],
   "source": [
    "stopwords=[\"er\",\"en\",\"da\",\"så\",\"men\",\"som\",\"der\",\"det\",\"i\",\"om\",\"man\",\"nok\",\"jeg\",\"over\"]\n",
    "wordlist_string=\"da jeg gik ud over Langebro var jeg i tvivl om det regnede, men det er jo ikke til at vide som man ved, så det er godt nok.\"\n",
    "wordlist=wordlist_string.split()\n",
    "print(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sol']\n"
     ]
    }
   ],
   "source": [
    "#testing different types of solutions\n",
    "stop=\"hejhej\"\n",
    "notstop=[\"hejhej\",\"sol\"]\n",
    "notstop.remove(stop)\n",
    "print(notstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#but this above is only possible when [stop] is a string, not a list\n",
    "#otherwise there is the following type of list comprehension - but here the same applies\n",
    "# = I need to stringify the stopwords\n",
    "glist=[word for word in wordlist if str(stopwords) in word]\n",
    "print(glist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to question 3.1.5 (with some help)\n",
    "#I want to write a function that kind of says \"newlist=wordlist-stopwords\" in a function.\n",
    "#det kan man dog ikke bare sådan\n",
    "\n",
    "#first I define the function\n",
    "def remove_stop_words(of_list,stopwords):\n",
    "    #then I make an empty list\n",
    "    stopfree=[]\n",
    "    #then if I could use the .remove-method when combining the two lists...\n",
    "    for element in of_list:\n",
    "        if element not in stopwords:\n",
    "            stopfree.append(element)\n",
    "    return stopfree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gik',\n",
       " 'ud',\n",
       " 'Langebro',\n",
       " 'var',\n",
       " 'tvivl',\n",
       " 'regnede,',\n",
       " 'jo',\n",
       " 'ikke',\n",
       " 'til',\n",
       " 'vide',\n",
       " 'ved,',\n",
       " 'godt',\n",
       " 'nok.']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words(wordlist,stopwords) #genialt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function: (does not work)\n",
    "def remove_stop_words(of_list):\n",
    "    #tell it that the stopwords-list is also working inside the function\n",
    "    global stopwords\n",
    "    #asking it to remove every stringified element in stopwords from the list applied\n",
    "    for each_element in stopwords:\n",
    "        #it doesn't get my point though\n",
    "        of_list.remove(str(each_element))\n",
    "    return of_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_stop_words(wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Text Files\n",
    "\n",
    "**Question 2.2.1**: Read in the text files `stop_words.txt` and turn it into a list of words. \n",
    "\n",
    "Note: when you look at the file you see that each word is on a different line. Remember to remove the newline characters for each line/word.\n",
    "\n",
    "Stopwords from: http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'do', 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "#Answer to question 2.2.1\n",
    "#opening the file\n",
    "stopwords_eng=[]\n",
    "textfile=open(\"stop_words.txt\",\"r\",errors=\"ignore\")\n",
    "#making an empty list for the words\n",
    "textlist=[]\n",
    "#looking through each element in textfile, stripping it of \\n and adding it to the list\n",
    "for element in textfile:\n",
    "    elemento=element.strip(\"\\n\")\n",
    "    stopwords_eng.append(elemento)\n",
    "#boohja\n",
    "print(stopwords_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.2**: Write a function `make_wordlist` that takes a filename as the argument. The function reads the file, turning the text to lower case and removes all non alpha-numeric characters. The function returns a list of all the words.  \n",
    "\n",
    "Hint: You will need to use a regular expression for only alphanumeric characters. Use `search(pattern, text)` and `group()` methods following the example in class.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#testing different expressions and methods to handle this before throwing into function!\n",
    "texttester_file=open(\"new_file.txt\",\"r\",errors=\"ignore\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "as_string=str(texttester_file).lower()\n",
    "annastest=re.match(\"h\",as_string)\n",
    "print(annastest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='<'>\n"
     ]
    }
   ],
   "source": [
    "testlist=re.search('(\\W)',as_string)\n",
    "print(testlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list\n",
    "listio=[]\n",
    "#telling it what we want to count as a word\n",
    "wordfind='(\\W+\\s)'\n",
    "#looping through all\n",
    "for element in texttester_file:\n",
    "    singled_word=re.search(wordfind,element)\n",
    "    if singled_word:\n",
    "        listio.append(singled_word.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(listio)\n",
    "#why does this not work???????\n",
    "#it must have something to do with the file types: the texttester_file is a file\n",
    "#not a list or a string\n",
    "#lets not give up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to Question 2.2.2 \n",
    "#needs library-search-functions in the re-library\n",
    "import re\n",
    "#defines the function\n",
    "def make_wordlist(filename):\n",
    "    #first it has to open the file under a new name (we don't want to alter the file) [=file]\n",
    "    import re\n",
    "    my_file=open(filename,'r', errors=\"ignore\")\n",
    "    my_list_for_later=[]\n",
    "    #then it needs to turn the text to lower case - .lower() [=as string]\n",
    "    my_text=my_file.read()\n",
    "    #I need to use split here, otherwise the characters will come out as 'h','e','j'\n",
    "    my_text_altered=my_text.lower().split()\n",
    "    #it needs to remove all non aplha-numeric characters (=not 123asd) [=string]\n",
    "    for each_letter in my_text_altered:\n",
    "        #I have some problems figuring out how to include \"i'm\"\n",
    "        unclean=re.search('\\w+|\\'',each_letter)\n",
    "        if unclean:\n",
    "            #group is able to do something here - it kind of puts the stuff together\n",
    "            #instead of metatexting it\n",
    "            my_list_for_later.append(unclean.group())\n",
    "            \n",
    "    return(my_list_for_later)\n",
    "            \n",
    "    #it then needs to return a list of the words through .group() (tror jeg) [=list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'writing',\n",
       " 'to',\n",
       " 'my',\n",
       " 'first',\n",
       " 'file',\n",
       " 'it',\n",
       " 'i',\n",
       " 's',\n",
       " 'really',\n",
       " 'niice',\n",
       " '142302139mds',\n",
       " '231']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_wordlist(\"new_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i’m',\n",
       " 'writing',\n",
       " 'to',\n",
       " 'my',\n",
       " 'first',\n",
       " 'file!',\n",
       " 'it',\n",
       " 'i',\n",
       " 's',\n",
       " 'really',\n",
       " 'niice',\n",
       " '142302139mds,',\n",
       " ';:€\"!€',\n",
       " '231\"!#\"#']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    my_file=open(\"new_file.txt\",'r', errors=\"ignore\")\n",
    "    my_list_for_later=[]\n",
    "    #then it needs to turn the text to lower case - .lower() [=as string]\n",
    "    my_text=my_file.read()\n",
    "    #I need to use split here, otherwise the characters will come out as 'h','e','j'\n",
    "    my_text_altered=my_text.lower().split()\n",
    "    my_text_altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what the instructors did:\n",
    "def make_wordlist_as_teacher(filename):\n",
    "    #importing regular expression library\n",
    "    import re\n",
    "    \n",
    "    #opening file\n",
    "    file = open(filename, 'r', errors = 'ignore')\n",
    "    \n",
    "    #reading the text\n",
    "    text = file.read()\n",
    "    \n",
    "    #turning the text into a lowercase list of words\n",
    "    #note because text.lower() returns a string,\n",
    "    #the split() method can be then called on that string\n",
    "    word_list = text.lower().split()\n",
    "    clean_list = []\n",
    "    \n",
    "    #Loop through all the words in the list\n",
    "    for w in word_list:\n",
    "        #strip the word of all non alphanumeric characters\n",
    "        clean_word = re.search('\\w+',w)\n",
    "        \n",
    "        #if the regular expression found a word\n",
    "        #add that word to our new list\n",
    "        if clean_word:\n",
    "            clean_list.append(clean_word.group())\n",
    "    \n",
    "    return clean_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'writing',\n",
       " 'to',\n",
       " 'my',\n",
       " 'first',\n",
       " 'file',\n",
       " 'it',\n",
       " 'i',\n",
       " 's',\n",
       " 'really',\n",
       " 'niice',\n",
       " '142302139mds',\n",
       " '231']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_wordlist_as_teacher(\"new_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texttester_list=[]\n",
    "for element in texttester:\n",
    "    import re\n",
    "    element.split(\"\\W\")\n",
    "    texttester_list.append(element)\n",
    "print(texttester_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "listing=[]\n",
    "for element in as_string:\n",
    "    aselement=element.split(str(re.search(\"(\\W)\",as_string)))\n",
    "    listing.append(aselement)\n",
    "    #please do not print the listing, it goes cray\n",
    "    #print(listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.3**: Putting the above together allows you to read a file, clean up the words to remove unwanted characters, and count the frequency of words in the text from the file. This results in a sorted list of words. \n",
    "\n",
    "Run the code below to count the frequency of words in `Speech_2019.txt`. This is the speech given by DK Prime Minister Mette Frederiksen at the opening of parliament. Original found [here](http://www.stm.dk/_p_14878.html).\n",
    "\n",
    "Write the resulting list of words frequencies to a new text file with an appropriate name. Have a look at the file, does it seem like all your functions are working as they should? \n",
    "\n",
    "Note: it is ok if you have words that are single letters or numbers. We'll work on improving our data cleaning techniques in later classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file and turn it into a list of words\n",
    "word_list = make_wordlist('Speech_2019.txt')\n",
    "#remove stop words from the list\n",
    "word_list = remove_stop_words(word_list,stopwords_eng)\n",
    "#count the frequency of different words\n",
    "word_dict = word_freq(word_list)\n",
    "#sort the list\n",
    "sorted_words = sort_freq_dict(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trust', 34),\n",
       " ('denmark', 30),\n",
       " ('welfare', 22),\n",
       " ('society', 20),\n",
       " ('new', 20),\n",
       " ('people', 16),\n",
       " ('government', 15),\n",
       " ('cooperation', 15),\n",
       " ('today', 14),\n",
       " ('just', 14),\n",
       " ('need', 13),\n",
       " ('danish', 13),\n",
       " ('children', 13),\n",
       " ('world', 12),\n",
       " ('time', 11),\n",
       " ('things', 11),\n",
       " ('say', 11),\n",
       " ('money', 11),\n",
       " ('like', 11),\n",
       " ('elderly', 11),\n",
       " ('climate', 11),\n",
       " ('better', 11),\n",
       " ('does', 10),\n",
       " ('care', 10),\n",
       " ('year', 9),\n",
       " ('want', 9),\n",
       " ('right', 9),\n",
       " ('policy', 9),\n",
       " ('make', 9),\n",
       " ('life', 9),\n",
       " ('know', 9),\n",
       " ('home', 9),\n",
       " ('future', 9),\n",
       " ('folketing', 9),\n",
       " ('country', 9),\n",
       " ('tax', 8),\n",
       " ('police', 8),\n",
       " ('important', 8),\n",
       " ('help', 8),\n",
       " ('actually', 8),\n",
       " ('work', 7),\n",
       " ('way', 7),\n",
       " ('think', 7),\n",
       " ('green', 7),\n",
       " ('good', 7),\n",
       " ('forward', 7),\n",
       " ('employees', 7),\n",
       " ('citizen', 7),\n",
       " ('built', 7),\n",
       " ('working', 6),\n",
       " ('step', 6),\n",
       " ('said', 6),\n",
       " ('responsibility', 6),\n",
       " ('problems', 6),\n",
       " ('prime', 6),\n",
       " ('pay', 6),\n",
       " ('minister', 6),\n",
       " ('look', 6),\n",
       " ('live', 6),\n",
       " ('let', 6),\n",
       " ('greenland', 6),\n",
       " ('going', 6),\n",
       " ('free', 6),\n",
       " ('did', 6),\n",
       " ('day', 6),\n",
       " ('community', 6),\n",
       " ('come', 6),\n",
       " ('wish', 5),\n",
       " ('war', 5),\n",
       " ('social', 5),\n",
       " ('school', 5),\n",
       " ('places', 5),\n",
       " ('jobs', 5),\n",
       " ('islands', 5),\n",
       " ('immigration', 5),\n",
       " ('faroe', 5),\n",
       " ('example', 5),\n",
       " ('everyday', 5),\n",
       " ('education', 5),\n",
       " ('difficult', 5),\n",
       " ('course', 5),\n",
       " ('countries', 5),\n",
       " ('controlling', 5),\n",
       " ('completely', 5),\n",
       " ('common', 5),\n",
       " ('citizens', 5),\n",
       " ('changes', 5),\n",
       " ('budget', 5),\n",
       " ('billions', 5),\n",
       " ('best', 5),\n",
       " ('authorities', 5),\n",
       " ('young', 4),\n",
       " ('yes', 4),\n",
       " ('years', 4),\n",
       " ('violence', 4),\n",
       " ('understand', 4),\n",
       " ('timetables', 4),\n",
       " ('strengthen', 4),\n",
       " ('spend', 4),\n",
       " ('solve', 4),\n",
       " ('shall', 4),\n",
       " ('safe', 4),\n",
       " ('risk', 4),\n",
       " ('rights', 4),\n",
       " ('retirement', 4),\n",
       " ('results', 4),\n",
       " ('remember', 4),\n",
       " ('really', 4),\n",
       " ('proud', 4),\n",
       " ('politicians', 4),\n",
       " ('party', 4),\n",
       " ('nursing', 4),\n",
       " ('number', 4),\n",
       " ('municipalities', 4),\n",
       " ('minutes', 4),\n",
       " ('makes', 4),\n",
       " ('long', 4),\n",
       " ('legislation', 4),\n",
       " ('lead', 4),\n",
       " ('integration', 4),\n",
       " ('instead', 4),\n",
       " ('human', 4),\n",
       " ('history', 4),\n",
       " ('great', 4),\n",
       " ('fact', 4),\n",
       " ('europe', 4),\n",
       " ('enter', 4),\n",
       " ('don', 4),\n",
       " ('danes', 4),\n",
       " ('crisis', 4),\n",
       " ('create', 4),\n",
       " ('businesses', 4),\n",
       " ('based', 4),\n",
       " ('background', 4),\n",
       " ('ask', 4),\n",
       " ('areas', 4),\n",
       " ('worn', 3),\n",
       " ('words', 3),\n",
       " ('used', 3),\n",
       " ('task', 3),\n",
       " ('taken', 3),\n",
       " ('strategies', 3),\n",
       " ('stop', 3),\n",
       " ('start', 3),\n",
       " ('speaking', 3),\n",
       " ('solidarity', 3),\n",
       " ('seriously', 3),\n",
       " ('sense', 3),\n",
       " ('rules', 3),\n",
       " ('regions', 3),\n",
       " ('refugees', 3),\n",
       " ('real', 3),\n",
       " ('quite', 3),\n",
       " ('provide', 3),\n",
       " ('problem', 3),\n",
       " ('possibilities', 3),\n",
       " ('population', 3),\n",
       " ('politics', 3),\n",
       " ('political', 3),\n",
       " ('point', 3),\n",
       " ('plastic', 3),\n",
       " ('peoples', 3),\n",
       " ('order', 3),\n",
       " ('opportunity', 3),\n",
       " ('opening', 3),\n",
       " ('old', 3),\n",
       " ('night', 3),\n",
       " ('necessary', 3),\n",
       " ('model', 3),\n",
       " ('means', 3),\n",
       " ('longer', 3),\n",
       " ('local', 3),\n",
       " ('living', 3),\n",
       " ('little', 3),\n",
       " ('left', 3),\n",
       " ('justice', 3),\n",
       " ('international', 3),\n",
       " ('hope', 3),\n",
       " ('hooray', 3),\n",
       " ('honest', 3),\n",
       " ('homes', 3),\n",
       " ('held', 3),\n",
       " ('healthcare', 3),\n",
       " ('greener', 3),\n",
       " ('greater', 3),\n",
       " ('given', 3),\n",
       " ('feeling', 3),\n",
       " ('far', 3),\n",
       " ('faith', 3),\n",
       " ('failed', 3),\n",
       " ('environment', 3),\n",
       " ('energy', 3),\n",
       " ('direction', 3),\n",
       " ('development', 3),\n",
       " ('demands', 3),\n",
       " ('demanding', 3),\n",
       " ('demand', 3),\n",
       " ('cuts', 3),\n",
       " ('crime', 3),\n",
       " ('control', 3),\n",
       " ('clear', 3),\n",
       " ('cleaning', 3),\n",
       " ('carry', 3),\n",
       " ('business', 3),\n",
       " ('big', 3),\n",
       " ('believe', 3),\n",
       " ('beginning', 3),\n",
       " ('asylum', 3),\n",
       " ('ahead', 3),\n",
       " ('actual', 3),\n",
       " ('written', 2),\n",
       " ('worry', 2),\n",
       " ('worlds', 2),\n",
       " ('works', 2),\n",
       " ('workplaces', 2),\n",
       " ('word', 2),\n",
       " ('weaker', 2),\n",
       " ('water', 2),\n",
       " ('watching', 2),\n",
       " ('wants', 2),\n",
       " ('visit', 2),\n",
       " ('version', 2),\n",
       " ('values', 2),\n",
       " ('unnecessary', 2),\n",
       " ('unity', 2),\n",
       " ('understanding', 2),\n",
       " ('try', 2),\n",
       " ('trusting', 2),\n",
       " ('transition', 2),\n",
       " ('training', 2),\n",
       " ('trade', 2),\n",
       " ('timetable', 2),\n",
       " ('tight', 2),\n",
       " ('thank', 2),\n",
       " ('terms', 2),\n",
       " ('taxes', 2),\n",
       " ('tasks', 2),\n",
       " ('taking', 2),\n",
       " ('succeed', 2),\n",
       " ('strong', 2),\n",
       " ('strength', 2),\n",
       " ('strawberry', 2),\n",
       " ('steer', 2),\n",
       " ('statistics', 2),\n",
       " ('stands', 2),\n",
       " ('standing', 2),\n",
       " ('spent', 2),\n",
       " ('spending', 2),\n",
       " ('soon', 2),\n",
       " ('somewhat', 2),\n",
       " ('solved', 2),\n",
       " ('solutions', 2),\n",
       " ('smith', 2),\n",
       " ('single', 2),\n",
       " ('simple', 2),\n",
       " ('shower', 2),\n",
       " ('shouldn', 2),\n",
       " ('shift', 2),\n",
       " ('share', 2),\n",
       " ('sf', 2),\n",
       " ('set', 2),\n",
       " ('services', 2),\n",
       " ('sad', 2),\n",
       " ('result', 2),\n",
       " ('restrictive', 2),\n",
       " ('respect', 2),\n",
       " ('research', 2),\n",
       " ('regards', 2),\n",
       " ('regarding', 2),\n",
       " ('reduce', 2),\n",
       " ('recognize', 2),\n",
       " ('reckless', 2),\n",
       " ('rebuilding', 2),\n",
       " ('radikale', 2),\n",
       " ('quality', 2),\n",
       " ('provides', 2),\n",
       " ('project', 2),\n",
       " ('progress', 2),\n",
       " ('private', 2),\n",
       " ('prepared', 2),\n",
       " ('precise', 2),\n",
       " ('praise', 2),\n",
       " ('powerlessness', 2),\n",
       " ('possible', 2),\n",
       " ('policies', 2),\n",
       " ('plain', 2),\n",
       " ('picture', 2),\n",
       " ('peace', 2),\n",
       " ('parliamentary', 2),\n",
       " ('parliament', 2),\n",
       " ('parent', 2),\n",
       " ('opportunities', 2),\n",
       " ('nurses', 2),\n",
       " ('notice', 2),\n",
       " ('nature', 2),\n",
       " ('mutual', 2),\n",
       " ('municipal', 2),\n",
       " ('mps', 2),\n",
       " ('mobility', 2),\n",
       " ('mistakes', 2),\n",
       " ('meetings', 2),\n",
       " ('market', 2),\n",
       " ('majority', 2),\n",
       " ('low', 2),\n",
       " ('lot', 2),\n",
       " ('lose', 2),\n",
       " ('lies', 2),\n",
       " ('liberal', 2),\n",
       " ('legislate', 2),\n",
       " ('learn', 2),\n",
       " ('leadership', 2),\n",
       " ('labour', 2),\n",
       " ('kroners', 2),\n",
       " ('kilos', 2),\n",
       " ('journey', 2),\n",
       " ('join', 2),\n",
       " ('job', 2),\n",
       " ('instance', 2),\n",
       " ('inequality', 2),\n",
       " ('industry', 2),\n",
       " ('improved', 2),\n",
       " ('improve', 2),\n",
       " ('immigrants', 2),\n",
       " ('hold', 2),\n",
       " ('having', 2),\n",
       " ('happened', 2),\n",
       " ('hall', 2),\n",
       " ('half', 2),\n",
       " ('growth', 2),\n",
       " ('greed', 2),\n",
       " ('goal', 2),\n",
       " ('generation', 2),\n",
       " ('funds', 2),\n",
       " ('fundamental', 2),\n",
       " ('freely', 2),\n",
       " ('foreign', 2),\n",
       " ('firm', 2),\n",
       " ('fewer', 2),\n",
       " ('feel', 2),\n",
       " ('fantastic', 2),\n",
       " ('family', 2),\n",
       " ('export', 2),\n",
       " ('experience', 2),\n",
       " ('european', 2),\n",
       " ('equally', 2),\n",
       " ('entire', 2),\n",
       " ('enhedslisten', 2),\n",
       " ('engineer', 2),\n",
       " ('emerged', 2),\n",
       " ('economic', 2),\n",
       " ('ecology', 2),\n",
       " ('easy', 2),\n",
       " ('drowning', 2),\n",
       " ('driving', 2),\n",
       " ('doing', 2),\n",
       " ('documentation', 2),\n",
       " ('dissent', 2),\n",
       " ('different', 2),\n",
       " ('didn', 2),\n",
       " ('democracy', 2),\n",
       " ('deer', 2),\n",
       " ('decades', 2),\n",
       " ('crimes', 2),\n",
       " ('courses', 2),\n",
       " ('corporations', 2),\n",
       " ('contribute', 2),\n",
       " ('contrary', 2),\n",
       " ('contract', 2),\n",
       " ('continue', 2),\n",
       " ('compromise', 2),\n",
       " ('company', 2),\n",
       " ('comes', 2),\n",
       " ('colleague', 2),\n",
       " ('closer', 2),\n",
       " ('closeness', 2),\n",
       " ('close', 2),\n",
       " ('clearly', 2),\n",
       " ('clean', 2),\n",
       " ('christiansborg', 2),\n",
       " ('choose', 2),\n",
       " ('child', 2),\n",
       " ('change', 2),\n",
       " ('chance', 2),\n",
       " ('challenges', 2),\n",
       " ('certain', 2),\n",
       " ('centre', 2),\n",
       " ('case', 2),\n",
       " ('build', 2),\n",
       " ('bring', 2),\n",
       " ('border', 2),\n",
       " ('booth', 2),\n",
       " ('bit', 2),\n",
       " ('begin', 2),\n",
       " ('bed', 2),\n",
       " ('battle', 2),\n",
       " ('banditry', 2),\n",
       " ('away', 2),\n",
       " ('august', 2),\n",
       " ('asked', 2),\n",
       " ('answer', 2),\n",
       " ('amounts', 2),\n",
       " ('ambitions', 2),\n",
       " ('ambition', 2),\n",
       " ('alliance', 2),\n",
       " ('agreements', 2),\n",
       " ('agreement', 2),\n",
       " ('agreed', 2),\n",
       " ('adolescents', 2),\n",
       " ('address', 2),\n",
       " ('additional', 2),\n",
       " ('add', 2),\n",
       " ('accountable', 2),\n",
       " ('able', 2),\n",
       " ('youth', 1),\n",
       " ('wrong', 1),\n",
       " ('worth', 1),\n",
       " ('worse', 1),\n",
       " ('worried', 1),\n",
       " ('worldwide', 1),\n",
       " ('workplace', 1),\n",
       " ('workforce', 1),\n",
       " ('workers', 1),\n",
       " ('woods', 1),\n",
       " ('wonder', 1),\n",
       " ('won', 1),\n",
       " ('women', 1),\n",
       " ('witnesses', 1),\n",
       " ('wishes', 1),\n",
       " ('wiser', 1),\n",
       " ('wing', 1),\n",
       " ('wind', 1),\n",
       " ('willingness', 1),\n",
       " ('wildlife', 1),\n",
       " ('wider', 1),\n",
       " ('welcome', 1),\n",
       " ('wealth', 1),\n",
       " ('waste', 1),\n",
       " ('wars', 1),\n",
       " ('warriors', 1),\n",
       " ('warmth', 1),\n",
       " ('walking', 1),\n",
       " ('walk', 1),\n",
       " ('wake', 1),\n",
       " ('waiting', 1),\n",
       " ('vulnerable', 1),\n",
       " ('voters', 1),\n",
       " ('vocational', 1),\n",
       " ('visiting', 1),\n",
       " ('visionary', 1),\n",
       " ('violations', 1),\n",
       " ('video', 1),\n",
       " ('valuable', 1),\n",
       " ('vacuum', 1),\n",
       " ('use', 1),\n",
       " ('unsafe', 1),\n",
       " ('unrest', 1),\n",
       " ('university', 1),\n",
       " ('universities', 1),\n",
       " ('units', 1),\n",
       " ('unites', 1),\n",
       " ('unique', 1),\n",
       " ('unions', 1),\n",
       " ('unify', 1),\n",
       " ('unguarded', 1),\n",
       " ('unevenly', 1),\n",
       " ('unemployment', 1),\n",
       " ('uncovered', 1),\n",
       " ('ultimately', 1),\n",
       " ('tyranny', 1),\n",
       " ('twice', 1),\n",
       " ('turn', 1),\n",
       " ('turll', 1),\n",
       " ('turbines', 1),\n",
       " ('truth', 1),\n",
       " ('trivial', 1),\n",
       " ('trees', 1),\n",
       " ('treatment', 1),\n",
       " ('treasury', 1),\n",
       " ('transportation', 1),\n",
       " ('transport', 1),\n",
       " ('traffickers', 1),\n",
       " ('traces', 1),\n",
       " ('tough', 1),\n",
       " ('touched', 1),\n",
       " ('torn', 1),\n",
       " ('torch', 1),\n",
       " ('topic', 1),\n",
       " ('tomorrow', 1),\n",
       " ('toll', 1),\n",
       " ('toiled', 1),\n",
       " ('times', 1),\n",
       " ('tighter', 1),\n",
       " ('tightenings', 1),\n",
       " ('threats', 1),\n",
       " ('thousands', 1),\n",
       " ('thought', 1),\n",
       " ('thinks', 1),\n",
       " ('thinking', 1),\n",
       " ('terrorism', 1),\n",
       " ('territory', 1),\n",
       " ('tend', 1),\n",
       " ('tempted', 1),\n",
       " ('tell', 1),\n",
       " ('technology', 1),\n",
       " ('teachers', 1),\n",
       " ('target', 1),\n",
       " ('talk', 1),\n",
       " ('takes', 1),\n",
       " ('taker', 1),\n",
       " ('syria', 1),\n",
       " ('symbolics', 1),\n",
       " ('surveillance', 1),\n",
       " ('surprised', 1),\n",
       " ('sure', 1),\n",
       " ('supposed', 1),\n",
       " ('support', 1),\n",
       " ('supplier', 1),\n",
       " ('sunday', 1),\n",
       " ('sums', 1),\n",
       " ('summer', 1),\n",
       " ('sum', 1),\n",
       " ('suicide', 1),\n",
       " ('sugar', 1),\n",
       " ('sufficient', 1),\n",
       " ('streamlining', 1),\n",
       " ('stream', 1),\n",
       " ('strange', 1),\n",
       " ('story', 1),\n",
       " ('storms', 1),\n",
       " ('stories', 1),\n",
       " ('stomach', 1),\n",
       " ('stolen', 1),\n",
       " ('sticking', 1),\n",
       " ('stick', 1),\n",
       " ('steig', 1),\n",
       " ('stated', 1),\n",
       " ('stare', 1),\n",
       " ('stage', 1),\n",
       " ('stable', 1),\n",
       " ('stability', 1),\n",
       " ('stabbings', 1),\n",
       " ('spread', 1),\n",
       " ('sporting', 1),\n",
       " ('spoken', 1),\n",
       " ('spends', 1),\n",
       " ('speeches', 1),\n",
       " ('speech', 1),\n",
       " ('speculators', 1),\n",
       " ('specified', 1),\n",
       " ('space', 1),\n",
       " ('south', 1),\n",
       " ('source', 1),\n",
       " ('sons', 1),\n",
       " ('somebody', 1),\n",
       " ('solid', 1),\n",
       " ('socialist', 1),\n",
       " ('soccer', 1),\n",
       " ('slowly', 1),\n",
       " ('slightly', 1),\n",
       " ('skilful', 1),\n",
       " ('skat', 1),\n",
       " ('sjlsmark', 1),\n",
       " ('sitting', 1),\n",
       " ('significance', 1),\n",
       " ('sick', 1),\n",
       " ('shrugging', 1),\n",
       " ('shown', 1),\n",
       " ('showers', 1),\n",
       " ('showdowns', 1),\n",
       " ('shoulders', 1),\n",
       " ('shootings', 1),\n",
       " ('shape', 1),\n",
       " ('separate', 1),\n",
       " ('sentences', 1),\n",
       " ('sensing', 1),\n",
       " ('seen', 1),\n",
       " ('security', 1),\n",
       " ('secure', 1),\n",
       " ('sector', 1),\n",
       " ('second', 1),\n",
       " ('sea', 1),\n",
       " ('scroll', 1),\n",
       " ('schools', 1),\n",
       " ('scandal', 1),\n",
       " ('scale', 1),\n",
       " ('says', 1),\n",
       " ('saying', 1),\n",
       " ('safety', 1),\n",
       " ('running', 1),\n",
       " ('route', 1),\n",
       " ('rosy', 1),\n",
       " ('rooms', 1),\n",
       " ('roll', 1),\n",
       " ('role', 1),\n",
       " ('roadside', 1),\n",
       " ('road', 1),\n",
       " ('rise', 1),\n",
       " ('riding', 1),\n",
       " ('rid', 1),\n",
       " ('richer', 1),\n",
       " ('rich', 1),\n",
       " ('reunification', 1),\n",
       " ('return', 1),\n",
       " ('rest', 1),\n",
       " ('responsible', 1),\n",
       " ('responsibilities', 1),\n",
       " ('respond', 1),\n",
       " ('residents', 1),\n",
       " ('residential', 1),\n",
       " ('reprioritization', 1),\n",
       " ('representatives', 1),\n",
       " ('replaced', 1),\n",
       " ('repetition', 1),\n",
       " ('relations', 1),\n",
       " ('rejected', 1),\n",
       " ('regulate', 1),\n",
       " ('regress', 1),\n",
       " ('region', 1),\n",
       " ('regardless', 1),\n",
       " ('reform', 1),\n",
       " ('refocus', 1),\n",
       " ('referendum', 1),\n",
       " ('red', 1),\n",
       " ('record', 1),\n",
       " ('recognise', 1),\n",
       " ('ready', 1),\n",
       " ('ranks', 1),\n",
       " ('quickly', 1),\n",
       " ('questions', 1),\n",
       " ('question', 1),\n",
       " ('punished', 1),\n",
       " ('publish', 1),\n",
       " ('public', 1),\n",
       " ('pseudo', 1),\n",
       " ('proposal', 1),\n",
       " ('promising', 1),\n",
       " ('promise', 1),\n",
       " ('prolonged', 1),\n",
       " ('progressive', 1),\n",
       " ('progressing', 1),\n",
       " ('program', 1),\n",
       " ('professionalism', 1),\n",
       " ('produced', 1),\n",
       " ('process', 1),\n",
       " ('prisons', 1),\n",
       " ('prioritize', 1),\n",
       " ('price', 1),\n",
       " ('prevent', 1),\n",
       " ('pretending', 1),\n",
       " ('pressure', 1),\n",
       " ('present', 1),\n",
       " ('preparation', 1),\n",
       " ('premier', 1),\n",
       " ('precious', 1),\n",
       " ('pram', 1),\n",
       " ('power', 1),\n",
       " ('positions', 1),\n",
       " ('position', 1),\n",
       " ('pollution', 1),\n",
       " ('politician', 1),\n",
       " ('plc', 1),\n",
       " ('play', 1),\n",
       " ('plant', 1),\n",
       " ('plans', 1),\n",
       " ('plan', 1),\n",
       " ('placing', 1),\n",
       " ('place', 1),\n",
       " ('physically', 1),\n",
       " ('pharmaceutical', 1),\n",
       " ('person', 1),\n",
       " ('percent', 1),\n",
       " ('pedagogical', 1),\n",
       " ('peaceful', 1),\n",
       " ('pays', 1),\n",
       " ('patient', 1),\n",
       " ('past', 1),\n",
       " ('passes', 1),\n",
       " ('parts', 1),\n",
       " ('partnerships', 1),\n",
       " ('parties', 1),\n",
       " ('parents', 1),\n",
       " ('paradox', 1),\n",
       " ('paradigm', 1),\n",
       " ('paper', 1),\n",
       " ('painting', 1),\n",
       " ('painted', 1),\n",
       " ('paid', 1),\n",
       " ('pace', 1),\n",
       " ('overall', 1),\n",
       " ('outside', 1),\n",
       " ('ought', 1),\n",
       " ('origin', 1),\n",
       " ('opposite', 1),\n",
       " ('open', 1),\n",
       " ('ones', 1),\n",
       " ('older', 1),\n",
       " ('oldboys', 1),\n",
       " ('october', 1),\n",
       " ('oceans', 1),\n",
       " ('occasions', 1),\n",
       " ('numbers', 1),\n",
       " ('noticeably', 1),\n",
       " ('noses', 1),\n",
       " ('north', 1),\n",
       " ('non', 1),\n",
       " ('nielsen', 1),\n",
       " ('news', 1),\n",
       " ('neighbourhood', 1),\n",
       " ('needs', 1),\n",
       " ('needed', 1),\n",
       " ('near', 1),\n",
       " ('national', 1),\n",
       " ('naalakkersuisut', 1),\n",
       " ('moving', 1),\n",
       " ('mistrust', 1),\n",
       " ('misery', 1),\n",
       " ('miracles', 1),\n",
       " ('minute', 1),\n",
       " ('mint', 1),\n",
       " ('mines', 1),\n",
       " ('million', 1),\n",
       " ('midwives', 1),\n",
       " ('micro', 1),\n",
       " ('mette', 1),\n",
       " ('met', 1),\n",
       " ('message', 1),\n",
       " ('men', 1),\n",
       " ('members', 1),\n",
       " ('melting', 1),\n",
       " ('meeting', 1),\n",
       " ('meet', 1),\n",
       " ('mediterranean', 1),\n",
       " ('medicine', 1),\n",
       " ('medication', 1),\n",
       " ('medical', 1),\n",
       " ('measured', 1),\n",
       " ('maybe', 1),\n",
       " ('massive', 1),\n",
       " ('maritime', 1),\n",
       " ('mandates', 1),\n",
       " ('management', 1),\n",
       " ('manage', 1),\n",
       " ('man', 1),\n",
       " ('male', 1),\n",
       " ('making', 1),\n",
       " ('luckily', 1),\n",
       " ('lrerseminarium', 1),\n",
       " ('lovely', 1),\n",
       " ('love', 1),\n",
       " ('lost', 1),\n",
       " ('losing', 1),\n",
       " ('loosening', 1),\n",
       " ('looks', 1),\n",
       " ('looking', 1),\n",
       " ('looked', 1),\n",
       " ('ll', 1),\n",
       " ('litany', 1),\n",
       " ('listen', 1),\n",
       " ('lingo', 1),\n",
       " ('lifted', 1),\n",
       " ('lie', 1),\n",
       " ('library', 1),\n",
       " ('liberated', 1),\n",
       " ('level', 1),\n",
       " ('letting', 1),\n",
       " ('lengths', 1),\n",
       " ('legislative', 1),\n",
       " ('legislating', 1),\n",
       " ('leave', 1),\n",
       " ('learning', 1),\n",
       " ('learned', 1),\n",
       " ('leading', 1),\n",
       " ('lay', 1),\n",
       " ('law', 1),\n",
       " ('laugh', 1),\n",
       " ('late', 1),\n",
       " ('large', 1),\n",
       " ('lady', 1),\n",
       " ('lack', 1),\n",
       " ('knowledge', 1),\n",
       " ('knowing', 1),\n",
       " ('kind', 1),\n",
       " ('kim', 1),\n",
       " ('kielsen', 1),\n",
       " ('jutland', 1),\n",
       " ('judicial', 1),\n",
       " ('judgement', 1),\n",
       " ('jeg', 1),\n",
       " ('issues', 1),\n",
       " ('involvement', 1),\n",
       " ('involved', 1),\n",
       " ('invite', 1),\n",
       " ('invitation', 1),\n",
       " ('investments', 1),\n",
       " ('invest', 1),\n",
       " ('internship', 1),\n",
       " ('intentions', 1),\n",
       " ('intend', 1),\n",
       " ('insurmountable', 1),\n",
       " ('institutions', 1),\n",
       " ('insecurity', 1),\n",
       " ('initiated', 1),\n",
       " ('informed', 1),\n",
       " ('information', 1),\n",
       " ('inflate', 1),\n",
       " ('individuals', 1),\n",
       " ('increases', 1),\n",
       " ('inclusion', 1),\n",
       " ('improving', 1),\n",
       " ('idea', 1),\n",
       " ('ice', 1),\n",
       " ('hverdagen', 1),\n",
       " ('hurricanes', 1),\n",
       " ('humans', 1),\n",
       " ('humane', 1),\n",
       " ('huge', 1),\n",
       " ('hospitals', 1),\n",
       " ('horrors', 1),\n",
       " ('hopefully', 1),\n",
       " ('honour', 1),\n",
       " ('holy', 1),\n",
       " ('holding', 1),\n",
       " ('holder', 1),\n",
       " ('historic', 1),\n",
       " ('hired', 1),\n",
       " ('himmerland', 1),\n",
       " ('high', 1),\n",
       " ('helped', 1),\n",
       " ('health', 1),\n",
       " ('headlines', 1),\n",
       " ('heading', 1),\n",
       " ('head', 1),\n",
       " ('hard', 1),\n",
       " ('happens', 1),\n",
       " ('hang', 1),\n",
       " ('handed', 1),\n",
       " ('grows', 1),\n",
       " ('grown', 1),\n",
       " ('groups', 1),\n",
       " ('ground', 1),\n",
       " ('greenlandic', 1),\n",
       " ('greenhouse', 1),\n",
       " ('granted', 1),\n",
       " ('grand', 1),\n",
       " ('gradually', 1),\n",
       " ('grabs', 1),\n",
       " ('governance', 1),\n",
       " ('gone', 1),\n",
       " ('gold', 1),\n",
       " ('globe', 1),\n",
       " ('global', 1),\n",
       " ('giving', 1),\n",
       " ('getting', 1),\n",
       " ('germany', 1),\n",
       " ('genocide', 1),\n",
       " ('generations', 1),\n",
       " ('general', 1),\n",
       " ('gas', 1),\n",
       " ('gang', 1),\n",
       " ('funen', 1),\n",
       " ('fund', 1),\n",
       " ('frontline', 1),\n",
       " ('frightening', 1),\n",
       " ('friends', 1),\n",
       " ('freedoms', 1),\n",
       " ('frederiksen', 1),\n",
       " ('frame', 1),\n",
       " ('foundation', 1),\n",
       " ('formed', 1),\n",
       " ('forgotten', 1),\n",
       " ('forgot', 1),\n",
       " ('forests', 1),\n",
       " ('foreigners', 1),\n",
       " ('forced', 1),\n",
       " ('force', 1),\n",
       " ('fooled', 1),\n",
       " ('food', 1),\n",
       " ('fond', 1),\n",
       " ('follows', 1),\n",
       " ('following', 1),\n",
       " ('follow', 1),\n",
       " ('folkeparti', 1),\n",
       " ('focused', 1),\n",
       " ('floor', 1),\n",
       " ('fleeing', 1),\n",
       " ('fish', 1),\n",
       " ('finish', 1),\n",
       " ('fine', 1),\n",
       " ('filled', 1),\n",
       " ('figuring', 1),\n",
       " ('fighting', 1),\n",
       " ('fight', 1),\n",
       " ('festive', 1),\n",
       " ('fellowship', 1),\n",
       " ('feeding', 1),\n",
       " ('faster', 1),\n",
       " ('fast', 1),\n",
       " ('faded', 1),\n",
       " ('eye', 1),\n",
       " ('extent', 1),\n",
       " ('extend', 1),\n",
       " ('explosions', 1),\n",
       " ('explanation', 1),\n",
       " ('expand', 1),\n",
       " ('existing', 1),\n",
       " ('existence', 1),\n",
       " ('excellent', 1),\n",
       " ('evil', 1),\n",
       " ('evidently', 1),\n",
       " ('evasions', 1),\n",
       " ('evasion', 1),\n",
       " ('equal', 1),\n",
       " ('environmental', 1),\n",
       " ('enthusiasm', 1),\n",
       " ('enormous', 1),\n",
       " ('engage', 1),\n",
       " ('employment', 1),\n",
       " ('employee', 1),\n",
       " ('employed', 1),\n",
       " ('employ', 1),\n",
       " ('emission', 1),\n",
       " ('elements', 1),\n",
       " ('election', 1),\n",
       " ('efforts', 1),\n",
       " ('efficiency', 1),\n",
       " ('educated', 1),\n",
       " ('economy', 1),\n",
       " ('economically', 1),\n",
       " ('eat', 1),\n",
       " ('early', 1),\n",
       " ('ear', 1),\n",
       " ('duties', 1),\n",
       " ('driven', 1),\n",
       " ('drinking', 1),\n",
       " ('drawing', 1),\n",
       " ('draw', 1),\n",
       " ('draining', 1),\n",
       " ('doubts', 1),\n",
       " ('doubt', 1),\n",
       " ('doctors', 1),\n",
       " ('distributing', 1),\n",
       " ('distributed', 1),\n",
       " ('distant', 1),\n",
       " ('disappears', 1),\n",
       " ('disappear', 1),\n",
       " ('dilemmas', 1),\n",
       " ('dilemma', 1),\n",
       " ('differences', 1),\n",
       " ('despair', 1),\n",
       " ('deserve', 1),\n",
       " ('descendants', 1),\n",
       " ('demographics', 1),\n",
       " ('democrats', 1),\n",
       " ('demanded', 1),\n",
       " ('deliver', 1),\n",
       " ('deeply', 1),\n",
       " ('deduct', 1),\n",
       " ('decreasing', 1),\n",
       " ('decreased', 1),\n",
       " ('decisions', 1),\n",
       " ('decide', 1),\n",
       " ('debate', 1),\n",
       " ('days', 1),\n",
       " ('daycare', 1),\n",
       " ('daughter', 1),\n",
       " ('dare', 1),\n",
       " ('dansk', 1),\n",
       " ('dan', 1),\n",
       " ('damage', 1),\n",
       " ('daily', 1),\n",
       " ('cultures', 1),\n",
       " ('crooks', 1),\n",
       " ('creativity', 1),\n",
       " ('created', 1),\n",
       " ('cracks', 1),\n",
       " ('cozy', 1),\n",
       " ('cows', 1),\n",
       " ('courage', 1),\n",
       " ('councils', 1),\n",
       " ('corrected', 1),\n",
       " ('cooperate', 1),\n",
       " ('contributions', 1),\n",
       " ('consideration', 1),\n",
       " ('conservatives', 1),\n",
       " ('connected', 1),\n",
       " ('conduct', 1),\n",
       " ('conditions', 1),\n",
       " ('concern', 1),\n",
       " ('complicated', 1),\n",
       " ('competent', 1),\n",
       " ('companies', 1),\n",
       " ('committing', 1),\n",
       " ('commits', 1),\n",
       " ('commit', 1),\n",
       " ('commentaries', 1),\n",
       " ('commemorate', 1),\n",
       " ('college', 1),\n",
       " ('colleagues', 1),\n",
       " ('collage', 1),\n",
       " ('cohesion', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Answer to question 2.2.3\n",
    "sorted_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 (More) Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.1**: Write a regular expression for a telephone number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer to Question 2.3.1* \n",
    "\n",
    "Note this cell is in markdown mode (why?) Well, anyways: a telephone number expression could be made like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numbers: '\\d'\n",
    "#+45/0045: '+45|0045'\n",
    "#an answer: '((+45|0045)(\\d+){7,8})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.2**: Write a regular expression for a URL. \n",
    "\n",
    "Note: For this exercise you can use a simple solution that does not account for all possible conditions, but will capture most URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer to Question 2.3.2* \n",
    "\n",
    "Note this cell is in markdown mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an answer: '(http+(\\.){3}\\w+\\.\\w)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Reflection\n",
    "**Question 2.4.1**: Write a brief paragraph reflecting on your experience learning programming today. What did you struggle with? What did you enjoy? What surprised you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to question 2.4.1\n",
    "#omg this was hard. It was also a lot of learning which is really nice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
